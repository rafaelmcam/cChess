{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cChess.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEVhnCGpeCHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cChess/ && git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YITCfHlmx65w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cChess && ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBet8Z0URdwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XZCIGmFPjEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "# img = load_img('cChess/Labels/n/0.png')  # this is a PIL image\n",
        "# x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "# x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "# # the .flow() command below generates batches of randomly transformed images\n",
        "# # and saves the results to the `preview/` directory\n",
        "# i = 0\n",
        "# for batch in datagen.flow(x, batch_size=1,\n",
        "#                           save_to_dir='preview', save_prefix='bishop', save_format='jpeg'):\n",
        "#     i += 1\n",
        "#     if i > 20:\n",
        "#         break  # otherwise the generator would loop indefinitely"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy_5mKWlR5cR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCXoGCabRc4N",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WDUrdBAUrPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(50,50,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (1, 1)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(13))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUO4PVXyVB1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'cChess/Labels',  # this is the target directory\n",
        "        target_size=(50, 50),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvGBITCWVdt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=3392 // batch_size,\n",
        "        epochs=50)\n",
        "model.save_weights('/cChess/Weights/first_try.h5')  # always save your weights after training or during training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDnJCBxMLFsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!\\cd cChess && mkdir Weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SA4oriDetNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC14LZSWWIPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfgteWLCg5Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split = 0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'cChess/Labels/',  # this is the target directory\n",
        "        target_size=(50, 50),  # all images will be resized to 150x150\n",
        "        batch_size=10000,\n",
        "        class_mode='categorical',\n",
        "subset = 'training')  # since we use binary_crossentropy loss, we need binary labels\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "        'cChess/Labels/',  # this is the target directory\n",
        "        target_size=(50, 50),  # all images will be resized to 150x150\n",
        "        batch_size=10000,\n",
        "        class_mode='categorical',\n",
        "subset = 'validation')  # since we use binary_crossentropy loss, we need binary labels\n",
        "x,y = train_generator.next()\n",
        "x_test, y_test = val_generator.next()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRxtzbaGKLlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x.shape\n",
        "plt.imshow(x[8])\n",
        "print(y[8])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ULBSQ8dKNs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3gEpFBXxhOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(16, (3, 3), input_shape=(50,50,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (1, 1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())# this converts our 3D feature maps to 1D feature vectors\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(12))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x,y, batch_size = 64, validation_split = 0.1, epochs = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRpRfX_okcHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred_rafael_otario = np.argmax(y_pred, axis = 1)\n",
        "y_test_rafael_otario = np.argmax(y_test, axis = 1)\n",
        "y_test_rafael_otario"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-NAMoyJjqKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    print(unique_labels(y_true, y_pred))\n",
        "  \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "class_names = ['B', 'K', 'N', 'P', 'Q', 'R', 'b', 'k', 'n', 'p', 'q', 'r']\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test_rafael_otario, y_pred_rafael_otario, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test_rafael_otario, y_pred_rafael_otario, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewYkRpxIkZ-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeGZ5LhRKO3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''This script goes along the blog post\n",
        "\"Building powerful image classification models using very little data\"\n",
        "from blog.keras.io.\n",
        "It uses data that can be downloaded at:\n",
        "https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "In our setup, we:\n",
        "- created a data/ folder\n",
        "- created train/ and validation/ subfolders inside data/\n",
        "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
        "- put the cat pictures index 0-999 in data/train/cats\n",
        "- put the cat pictures index 1000-1400 in data/validation/cats\n",
        "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
        "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
        "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
        "In summary, this is our directory structure:\n",
        "```\n",
        "data/\n",
        "    train/\n",
        "        dogs/\n",
        "            dog001.jpg\n",
        "            dog002.jpg\n",
        "            ...\n",
        "        cats/\n",
        "            cat001.jpg\n",
        "            cat002.jpg\n",
        "            ...\n",
        "    validation/\n",
        "        dogs/\n",
        "            dog001.jpg\n",
        "            dog002.jpg\n",
        "            ...\n",
        "        cats/\n",
        "            cat001.jpg\n",
        "            cat002.jpg\n",
        "            ...\n",
        "```\n",
        "'''\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "def save_bottlebeck_features(x,y, x_test, y_test):\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "    bottleneck_features_train = model.predict(\n",
        "        x)\n",
        "    bottleneck_features_test = model.predict(\n",
        "        x_test)\n",
        "    print(bottleneck_features_train.shape)\n",
        "    np.save(open('./cChess/Weights/bottleneck_features_train.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "    np.save(open('./cChess/Weights/bottleneck_labels.npy', 'wb'),\n",
        "            y)\n",
        "\n",
        "    np.save(open('./cChess/Weights/bottleneck_features_test.npy', 'wb'),\n",
        "            bottleneck_features_test)\n",
        "    np.save(open('./cChess/Weights/bottleneck_labels_test.npy', 'wb'),\n",
        "            y_test)\n",
        "\n",
        "def train_top_model():\n",
        "    train_data = np.load(open('./cChess/Weights/bottleneck_features_train.npy', \"rb\"))\n",
        "    train_labels = np.load(open('./cChess/Weights/bottleneck_labels.npy',\"rb\"))\n",
        "\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_split=.2)\n",
        "    model.save_weights(\"./cChess/Weights/bottleneck512.h5\")\n",
        "\n",
        "    return model\n",
        "save_bottlebeck_features(x,y, x_test,y_test)\n",
        "model = train_top_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOy_A4nwoGvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the VGG16 network\n",
        "bottleneck_features_test = np.load(open('./cChess/Weights/bottleneck_features_test.npy', \"rb\"))\n",
        "y_test = np.load(open('./cChess/Weights/bottleneck_labels_test.npy',\"rb\"))\n",
        "y_pred = model.predict(bottleneck_features_test)\n",
        "\n",
        "plt.imshow(x_test[5])\n",
        "print(y_pred[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SLRYD2RpEy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_pred_rafael_otario = np.argmax(y_pred, axis = 1)\n",
        "y_test_rafael_otario = np.argmax(y_test, axis = 1)\n",
        "y_test_rafael_otario"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0Hph0mCpYQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_rafael_otario"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h2243wmoG2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlveulv5oG91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    print(unique_labels(y_true, y_pred))\n",
        "  \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "class_names = ['B', 'K', 'N', 'P', 'Q', 'R', 'b', 'k', 'n', 'p', 'q', 'r']\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_test_rafael_otario, y_pred_rafael_otario, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_test_rafael_otario, y_pred_rafael_otario, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzxo1i4DrMWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rafael_datagen = ImageDataGenerator(rescale=1./255)\n",
        "rafael_generator = rafael_datagen.flow_from_directory(\n",
        "        'cChess/RandomBoard_TestSets/Blender Test Sets/Test Labels',  # this is the target directory\n",
        "        target_size=(50, 50),  # all images will be resized to 150x150\n",
        "        batch_size=10000,\n",
        "        class_mode='categorical')\n",
        "x_rafael, y_rafael = rafael_generator.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zve6AzNnr2zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rafael_bottleneck = model_vgg.predict(x_rafael)\n",
        "rafael_pred = model.predict(rafael_bottleneck)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8vvhpoOsD6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a= 9\n",
        "plt.imshow(x_rafael[a])\n",
        "print('Predict Probabilities: \\n', rafael_pred[a])\n",
        "print('Real Labels: \\n' ,y_rafael[a])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq4VMGHkjGUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDZJNGH4oGBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or-fUx1LLtaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joXXY7O3L-fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape\n",
        "model_vgg = applications.VGG16(include_top=False, weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_3oNzZ1y37k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cChess/RandomBoard_TestSets/photo5021654756254394396/ && mkdir _"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g243BInVmsc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'cChess/RandomBoard_TestSets/photo5021654756254394396/',  # this is the target directory\n",
        "        target_size=(50, 50),  # all images will be resized to 150x150\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH-kS0AHnK49",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYqGWGU4nL7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test, y_test = test_generator.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6BC6NGvzCN3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GROgqXSmzCrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bottleneck_features = model_vgg.predict(x_test)\n",
        "model.evaluate(bottleneck_features,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmPi494JnaDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=15\n",
        "plt.imshow(x_test[i])\n",
        "print(np.argmax(y_test[i]))\n",
        "bottleneck_features = model_vgg.predict(x_test[i].reshape((1,)+x_test[i].shape))\n",
        "print(np.argmax(model.predict(bottleneck_features)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyQvLRyTPfLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=1\n",
        "plt.imshow(x[i])\n",
        "print(np.argmax(y[i]))\n",
        "\n",
        "bottleneck_features = model_vgg.predict(x[i].reshape((1,)+x[i].shape))\n",
        "print(np.argmax(model.predict(bottleneck_features)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vprcijzyPlVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([\n",
        "              [1,2,3],\n",
        "              [4 ,5 ,6],\n",
        "              [7,8,9],\n",
        "              [10,11,12]\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym8MO7oCP8V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q0H1WTVP_3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxkHFEwAQENC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(a == np.array([1,2,3])).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgORZofKQGay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZju8JHEQYk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_bin = np.amin((y==np.array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ck4bBMSQfYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=18\n",
        "plt.imshow(x[i])\n",
        "print(y_bin[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hCVAmk6RcAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''This script goes along the blog post\n",
        "\"Building powerful image classification models using very little data\"\n",
        "from blog.keras.io.\n",
        "It uses data that can be downloaded at:\n",
        "https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "In our setup, we:\n",
        "- created a data/ folder\n",
        "- created train/ and validation/ subfolders inside data/\n",
        "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
        "- put the cat pictures index 0-999 in data/train/cats\n",
        "- put the cat pictures index 1000-1400 in data/validation/cats\n",
        "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
        "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
        "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
        "In summary, this is our directory structure:\n",
        "```\n",
        "data/\n",
        "    train/\n",
        "        dogs/\n",
        "            dog001.jpg\n",
        "            dog002.jpg\n",
        "            ...\n",
        "        cats/\n",
        "            cat001.jpg\n",
        "            cat002.jpg\n",
        "            ...\n",
        "    validation/\n",
        "        dogs/\n",
        "            dog001.jpg\n",
        "            dog002.jpg\n",
        "            ...\n",
        "        cats/\n",
        "            cat001.jpg\n",
        "            cat002.jpg\n",
        "            ...\n",
        "```\n",
        "'''\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "def save_bottlebeck_features_bin(x,y):\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "    bottleneck_features_train = model.predict(\n",
        "        x)\n",
        "    print(bottleneck_features_train.shape)\n",
        "    np.save(open('./cChess/Weights/bottleneck_features_train_bin.npy', 'wb'),\n",
        "            bottleneck_features_train)\n",
        "    np.save(open('./cChess/Weights/bottleneck_labels_bin.npy', 'wb'),\n",
        "            y)\n",
        "\n",
        "def train_top_model_bin():\n",
        "    train_data = np.load(open('./cChess/Weights/bottleneck_features_train_bin.npy', \"rb\"))\n",
        "    train_labels = np.load(open('./cChess/Weights/bottleneck_labels_bin.npy',\"rb\"))\n",
        "\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              validation_split=.2)\n",
        "    model.save_weights(\"./cChess/Weights/bottleneck512_bin.h5\")\n",
        "\n",
        "\n",
        "save_bottlebeck_features_bin(x,y_bin)\n",
        "train_top_model_bin()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EA2V7acR3QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cChess && git status"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gErUzU0ScJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cChess && git add ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhH1fAJeSehm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcnRMTWDS1va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cChess && git config --global user.email \"afonso.delgado@hotmail.com\"\n",
        "!cd cChess && git config --global user.name \"Afonso Delgado\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfEvpGh9TG6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cChess && git commit -m \"trying some convnets architectures (94% accuracy on 13-classes classification and 99-100% accuracy on blank-piece classification on validation data)\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvkzr57KTLWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd cChess && git push"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--8vBFGeTOAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}